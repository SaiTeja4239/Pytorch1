{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnnIqVrI1a59WRjnnaSp3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiTeja4239/Pytorch1/blob/main/pytorch3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8qqH-xdoXH5",
        "outputId": "bf6d3ca6-e1d1-46ea-8207-38f03ba94ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "one of the most common error in deep learning :shape learning"
      ],
      "metadata": {
        "id": "ZDtv6SyYoZrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shapes of matrix multiplication\n",
        "tensor_A=torch.tensor([[1,2],[3,4],[5,6]])\n",
        "tensor_B=torch.tensor([[7,10],[8,11],[9,12]])\n",
        "\n",
        "#torch.mm(tensor_A,tensor_B)# torch.mm is the same as torch.matmul\n",
        "torch.matmul(tensor_A,tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "s2Td6if4pc77",
        "outputId": "d9a7d219-5bab-42d0-b359-a8d828591aa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-69c9a87ce399>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#torch.mm(tensor_A,tensor_B)# torch.mm is the same as torch.matmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A.shape,tensor_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY5hmevorT2t",
        "outputId": "3bd9a699-b547-4b7b-e4d3-918b199a8717"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix the tensor shape issues , we can manipulate the shape of one of our tensors using a transpose\n",
        "\n",
        "a transpose switches the axes or dimensions of the given tensor"
      ],
      "metadata": {
        "id": "wghpdFeerc52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B,tensor_B.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4TZgPVQsVHs",
        "outputId": "32cab55e-c839-49d8-e6b3-aee8c04f885d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7, 10],\n",
              "         [ 8, 11],\n",
              "         [ 9, 12]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.T,tensor_B.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vow4yv_3r_3p",
        "outputId": "c6e1190e-37ad-4512-ffa2-5a1322484c4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The matrix multiplication operation works when tensor_B is transposed\n",
        "print(f\"original shapes:tensor_A={tensor_A.shape},tensor_B={tensor_B.shape}\")\n",
        "print(f\"New shapes:tensor_A={tensor_A.shape}(same shape as above),tensor_B.T={tensor_B.shape}\")\n",
        "print(f\"Multiplying :{tensor_A.shape} & {tensor_B.T.shape} <- inner dimensions must match\")\n",
        "print(\"output:\\n\")\n",
        "output=torch.matmul(tensor_A,tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\noutput shape:{output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8dmh9ztsb_I",
        "outputId": "2f7193e0-050b-4d8e-9b6f-492fb5f07731"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shapes:tensor_A=torch.Size([3, 2]),tensor_B=torch.Size([3, 2])\n",
            "New shapes:tensor_A=torch.Size([3, 2])(same shape as above),tensor_B.T=torch.Size([3, 2])\n",
            "Multiplying :torch.Size([3, 2]) & torch.Size([2, 3]) <- inner dimensions must match\n",
            "output:\n",
            "\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "output shape:torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding min,max,mean,sum,etc(tensor aggregation)"
      ],
      "metadata": {
        "id": "v4DYtRETvjv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a tensor\n",
        "x = torch.arange(1,100,10)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb01V_96xEZW",
        "outputId": "0fd13b6a-4fe0-41a7-8b5f-aaeac34a5215"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the min\n",
        "torch.min(x),x.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUKBr3zpAkw6",
        "outputId": "8d9eec90-efa1-43fe-b27c-c47f348c03f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the max\n",
        "torch.max(x),x.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpT49YpXAywB",
        "outputId": "76f24fe0-28fc-4432-f0fb-fa5f671c3e3e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the mean\n",
        "torch.mean(x.type(torch.float32)),x.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGf1e24NA8dK",
        "outputId": "6c2ad8a3-0011-4ce5-bb78-35fda3ef07ce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(46.), tensor(46.))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the sum\n",
        "torch.sum(x),x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7s_NuCBKIBgX",
        "outputId": "9ef1dcaf-455b-48c8-d03e-3fa761af9868"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finding the positional min and max"
      ],
      "metadata": {
        "id": "kBuhh_V8IXHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBq2kOBkIc47",
        "outputId": "e3877280-1bc1-40ec-8dbf-c6b6c77939ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the position in tensor that has the minimum value with argmin()->returns index position of target where the minimum value occer\n",
        "x.argmin()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AiOTRaxIjhr",
        "outputId": "5123409b-b829-4ad6-a70f-e07e388a35fe"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV9I0UykIj-1",
        "outputId": "9be69b5a-82a9-4db1-b9ae-5fd299892488"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find the position in tensor that has the maximum value with argmax()\n",
        "x.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypODgSltIqqU",
        "outputId": "7d3cf22d-5c68-44da-a50a-45cec88b74ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slNhXCclKU_P",
        "outputId": "8c9535be-3f56-40ec-e601-af83cadeca6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reshaping, stacking ,squeezing and unsqueezing tensors\n",
        "\n",
        "reshaping-reshapes an input tensor to a defined shape\n",
        "\n",
        "view- return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "\n",
        "stacking-combine multiple tensors on top of each other(vstack) or side by side(hatack)\n",
        "\n",
        "squeeze-removes all 1 dimensions from a tensor\n",
        "\n",
        "unsqueeze-add a 1 dimension to a target tensor\n",
        "\n",
        "permute - return a view of the input with dimensions permuted(swapped) in a certain way"
      ],
      "metadata": {
        "id": "ffrdY4C2K8G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets create a tensor\n",
        "import torch\n",
        "x = torch.arange(1.,10.)\n",
        "x,x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQniRgMFNs5c",
        "outputId": "ed4fa912-e992-4992-b30a-0ae13680ded5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add an extra dimension\n",
        "x_reshaped= x.reshape(1,9)\n",
        "x_reshaped,x_reshaped.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcrqFlsVNgoS",
        "outputId": "617ce413-8124-4449-c2e8-29b9f14fff12"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change the view\n",
        "z=x.view(1,9)\n",
        "z,z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQac67vSPUZS",
        "outputId": "7e556a8f-e9ef-4400-bb07-9333efa681b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chaging z changes x (becuse a view of a tensor shares teh same memory as tehe original input )\n",
        "z[:,0]=5\n",
        "z,x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZshsdZGPuyc",
        "outputId": "7bc89633-befa-4708-8f4a-0fbe57d82ec9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stack tensors on top of each other\n",
        "x_stacked = torch.stack([x,x,x,x],dim=1)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbKKqcIjQdsL",
        "outputId": "aaf2be77-3cc1-4b45-8a7a-b2e98d097bb7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() - removes all single dimensions from a target tensor\n",
        "print(f\"previous tensor:{x_reshaped}\")\n",
        "print(f\"previous shape:{x_reshaped.shape}\")\n",
        "#Remove extra dimensions from x_reshaped\n",
        "x_squeezed=x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor:{x_squeezed}\")\n",
        "print(f\"New shape:{x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWUhytR4RVt3",
        "outputId": "6049879d-aa62-43a1-962e-0409d1d441e6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previous tensor:tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "previous shape:torch.Size([9])\n",
            "\n",
            "New tensor:tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape:torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.unsqueeze() - adds a single dimension to a target tensor at specific dim(dimensions)\n",
        "print(f\"previous target: {x_squeezed}\")\n",
        "print(f\"previous shape:{x_squeezed.shape}\")\n",
        "\n",
        "#Add n extra dimension with unsqueeze\n",
        "x_unsqueezed=x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor:{x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMsCflhYRnQE",
        "outputId": "02a9bce1-f955-427a-dca8-d532871ea994"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "previous shape:torch.Size([9])\n",
            "\n",
            "New tensor:tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.permute-rearranges the dimensions of a target tensor in a specified order\n",
        "x_original=torch.rand(size=(224,224,3)) #[height,width,colour_channels]\n",
        "\n",
        "#permute the original tensor to rearrange the axis (or dim) order\n",
        "x_permuted=x_original.permute(2,0,1) #shifts axis 0->1,1->2,2->3\n",
        "\n",
        "print(f\"previous shape :{x_original.shape}\")\n",
        "print(f\"New shape:{x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GakTHLuARtjr",
        "outputId": "696cd841-152b-4015-8fbf-a4f1d305f744"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previous shape :torch.Size([224, 224, 3])\n",
            "New shape:torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0,0,0]=728218\n",
        "x_original[0,0,0],x_permuted[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmF91iXwR0ru",
        "outputId": "c895919f-a0e8-4f73-fce2-afdd823144f9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(728218.), tensor(728218.))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}